{
  "dataset_reader": {
    "class_name": "sq_reader",
    "valid_size": 2,
    "data_path": "{DOWNLOADS_PATH}/coqa/coqa_max_tok_{MAX_TOKENS}.json"
  },
  "dataset_iterator": {
    "class_name": "data_learning_iterator"
  },
  "chainer": {
    "in": ["question", "ignored"],
    "in_y": ["target"],
    "pipe": [
      {
        "config_path": "{CONFIGS_PATH}/doc_retrieval/bpr_en.json",
        "in": ["question"],
        "out": ["contexts"]
      },
      {
        "class_name": "torch_transformers_generative_qa_preprocessor",
        "vocab_file": "{TRANSFORMER}",
        "max_seq_length": 512,
        "in": ["question", "contexts", "target"],
        "out": ["input_ids", "attention_mask", "target_ids"]
      },
      {
        "class_name": "torch_generative_qa",
        "pretrained_transformer": "{TRANSFORMER}",
        "save_path": "{MODEL_PATH}/model",
        "load_path": "{MODEL_PATH}/model",
        "optimizer": "AdamW",
        "optimizer_parameters": {
          "lr": 3e-04,
          "weight_decay": 0.01,
          "betas": [0.9, 0.999],
          "eps": 1e-06
        },
        "learning_rate_drop_patience": 20,
        "learning_rate_drop_div": 1.5,
        "in": ["input_ids", "attention_mask"],
        "in_y": ["target_ids"],
        "out": ["answer", "ppl"]
      }
    ],
    "out": ["answer"]
  },
  "train": {
    "show_examples": false,
    "evaluation_targets": [
      "valid"
    ],
    "log_every_n_batches": 50,
    "val_every_n_batches": 500,
    "batch_size": 15,
    "validation_patience": 100,
    "metrics": [
      {
        "name": "ppl",
        "inputs": ["ppl"]
      },
      {
        "name": "sacrebleu",
        "inputs": ["target", "answer"]
      }
    ],
    "class_name": "torch_trainer"
  },
  "metadata": {
    "variables": {
      "MAX_TOKENS" : 50,
      "LOWERCASE": false,
      "TRANSFORMER": "t5-base",
      "ROOT_PATH": "~/.deeppavlov",
      "DOWNLOADS_PATH": "{ROOT_PATH}/downloads",
      "MODELS_PATH": "{ROOT_PATH}/models",
      "MODEL_PATH": "{MODELS_PATH}/generative_qa/first_train/coqa-{TRANSFORMER}-max-tok-{MAX_TOKENS}",
      "CONFIGS_PATH": "{DEEPPAVLOV_PATH}/configs"
    },
    "download": [
      {
        "url": "http://files.deeppavlov.ai/deeppavlov_data/generative_question_answering/model.pth.tar",
        "subdir": "{MODEL_PATH}"
      }
    ]
  }
}